dfm2 <- dfm(texts_corp, ngrams=2, ignoredFeatures=getProfanityWords())
dfm3 <- dfm(texts_corp, ngrams=3, ignoredFeatures=getProfanityWords())
dfm4 <- dfm(texts_corp, ngrams=4, ignoredFeatures=getProfanityWords())
dfm5 <- dfm(texts_corp, ngrams=5, ignoredFeatures=getProfanityWords())
# Create tables for quick search
dt1 <- data.table(ngram = features(dfm1), count = colSums(dfm1), key = "ngram")
dt2 <- data.table(ngram = features(dfm2), count = colSums(dfm2), key = "ngram")
dt3 <- data.table(ngram = features(dfm3), count = colSums(dfm3), key = "ngram")
dt4 <- data.table(ngram = features(dfm4), count = colSums(dfm4), key = "ngram")
dt5 <- data.table(ngram = features(dfm5), count = colSums(dfm5), key = "ngram")
# Prunning items with count less than 4
dt1 <- dt1[count>2]
dt2 <- dt2[count>2]
dt3 <- dt3[count>2]
dt4 <- dt4[count>2]
dt5 <- dt5[count>2]
nrow(dt1); nrow(dt2); nrow(dt3); nrow(dt4); nrow(dt5)
# Write tables to files
if(i==1) {
write.table(dt1, file="dt1gram", append=F, row.names=F, col.names=T)
write.table(dt2, file="dt2gram", append=F, row.names=F, col.names=T)
write.table(dt3, file="dt3gram", append=F, row.names=F, col.names=T)
write.table(dt4, file="dt4gram", append=F, row.names=F, col.names=T)
write.table(dt5, file="dt5gram", append=F, row.names=F, col.names=T)
} else {
write.table(dt1, file="dt1gram", append=T, row.names=F, col.names=F)
write.table(dt2, file="dt2gram", append=T, row.names=F, col.names=F)
write.table(dt3, file="dt3gram", append=T, row.names=F, col.names=F)
write.table(dt4, file="dt4gram", append=T, row.names=F, col.names=F)
write.table(dt5, file="dt5gram", append=T, row.names=F, col.names=F)
}
rm(list=ls(pattern="news"))
rm(list=ls(pattern="text"))
rm(list=ls(pattern="blog"))
rm(list=ls(pattern="twitt"))
rm(list=ls(pattern="sent"))
news <- read_lines("en_US.news.txt")
blogs <- read_lines("en_US.blogs.txt")
twitts <- read_lines("en_US.twitter.txt")
# Loop to process the data in parts
lnews <- length(news); lnint <- round(lnews/5L)
lblogs <- length(blogs); lbint <- round(lblogs/5L)
ltwitts <- length(twitts); ltint <- round(ltwitts/5L)
# Remove n-gram tables
if(file.exist("dt1gram")) file.remove("dt1gram")
if(file.exist("dt2gram")) file.remove("dt2gram")
if(file.exist("dt3gram")) file.remove("dt3gram")
if(file.exist("dt4gram")) file.remove("dt4gram")
if(file.exist("dt5gram")) file.remove("dt5gram")
rm(news,twitts)
news <- read_lines("en_US.news.txt")
blogs <- read_lines("en_US.blogs.txt")
twitts <- read_lines("en_US.twitter.txt")
# Loop to process the data in parts
lnews <- length(news); lnint <- round(lnews/5L)
lblogs <- length(blogs); lbint <- round(lblogs/5L)
ltwitts <- length(twitts); ltint <- round(ltwitts/5L)
# Remove n-gram tables
if(file.exists("dt1gram")) file.remove("dt1gram")
if(file.exists("dt2gram")) file.remove("dt2gram")
if(file.exists("dt3gram")) file.remove("dt3gram")
if(file.exists("dt4gram")) file.remove("dt4gram")
if(file.exists("dt5gram")) file.remove("dt5gram")
rm(news,twitts)
library(shiny)
runApp()
?trim
??trim
runApp()
word
nrows
ngrams
j
ngrams[j][[paste0("token",6L-i)]]
score
i
word
i
nextwordtable
nextwordtable[word]
nextwordtable["a"]
setkey(nextwordtable,"word")
nextwordtable["a"]
runApp()
word
nextwordtable
ngrams
paste0("token",6L-i)
word
typeof(word)
word
typeof(score)
ngrams
typeof(ngrams$word)
typeof(ngrams$token4)
runApp()
typeof(word)
as.character(word)
nextwordtable[word]
nextwordtable[as.character(word)]
setkey(nextwordtable,"word")
nextwordtable[as.character(word)]
runApp()
word
nextwordtable
typeof(nextwordtable$word)
nextwordtable[word]
nextwordtable[as.character(word)]
setkey(nextwordtable,word)
nextwordtable[as.character(word)]
nextwordtable[word]
str(nextwordtable)
setkey(nextwordtable,"word")
nextwordtable[word]
nextwordtable[as.character(word)]
runApp()
word
nextwordtable
prevscore
runApp()
# server.R
library(shiny)
library(data.table)
# returns string w/o leading or trailing whitespace
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
# load ngram data set
dt1 <- as.data.table(read.table("dt1gram", row.names=NULL, header=T))
dt2 <- as.data.table(read.table("dt2gram", row.names=NULL, header=T))
dt3 <- as.data.table(read.table("dt3gram", row.names=NULL, header=T))
dt4 <- as.data.table(read.table("dt4gram", row.names=NULL, header=T))
dt5 <- as.data.table(read.table("dt5gram", row.names=NULL, header=T))
setkey(dt1,ngram)
setkey(dt2,token1,token2)
setkey(dt3,token1,token2,token3)
setkey(dt4,token1,token2,token3,token4)
setkey(dt5,token1,token2,token3,token4,token5)
dts <- list(dt5,dt4,dt3,dt2,dt1)
word <- "Francisco"
dts[[1]][word]
dts[[1]][token5==word]
dts[[1]][token5=word]
dts[[1]][,,,,word]
dts[[1]][,token5=word]
dts[[1]][,token5=-word]
dts[[1]][,token5==word]
dts[[1]]["this"]
dts[[1]][token5=="this"]
dts[[1]][token5=="Francisco"]
dts[[4]][token2=="Francisco"]
runApp()
d1 <- dts[[4]][token2=="Francisco"]
nrow(d1)
d1 <- dts[[4]][token2=="this"]
nrow(d1)
d11 <- d1[unique(token4)]
d11 <- d1[unique(d1$token4)]
d11
d1
d11 <- d1[unique(d1$token1)]
unique(d1$token1)
d1 <- dts[[1]][token5=="this"]
d1
unique(d1$token4)
count(unique(d1$token4))
length(unique(d1$token4))
agram <- list("x","y","z")
agram[[1]]
agram[[2]]
agram[[length(agram)+1]] <- "t"
agram
ngram <- c(agram,"p")
ngram
head(dt5)
dt5[.("a","bachelors","degree","in"]
dt5[.("a","bachelors","degree","in")]
length(dt5[.("a","bachelors","degree","in")])
dt5[.("a","bachelors","degree","in","business")]$count
runApp()
nrows
ngrams
ibeg
agram[1]
dts[[1]][agram[1]]
dts[[1]][agram[[1]]
]
runApp()
ngrams
dt5[agram[[1]]]
nrow(dt5[agram[[1]]])
runApp()
input$KNSmoothing
lambda
ngramcount
nm1gcount
runApp()
rm(list=ls())
runApp()
shiny::runApp()
runApp()
score
input$KNSmoothing
runApp()
word
agram
D
k
top
runApp()
agram
runApp()
D
word
agram
c(agram,word)
word
c(agram, unfactor(word))
c(agram, unlist(word)
)
word
agram
typeof(word)
c(agram, as.character(word))
runApp()
typeof(word)
CKNi
CKNitot
dts[[k]][agram]
lambda
word
agram
a <- list("a","b","c")
a
a[[1]] <- NULL
a
runApp()
k
CKNi
CKNitot
agram
runApp()
top
runApp()
agram
word
agram
dts[[k]][agram]
runApp()
ngram
runApp()
agram
ngram
k
dts[[k]]
dts[[k]][token2==agram[[1]] && token3==agram[[2]]]
agram[[1]]
agram[[2]]
setkey(dts[[k]],token2,token3,token4)
dts[[k]][agram]
setkey(dts[[k]],token1,token2,token3,token4)
dts[[k]][agram]
ngram
agram
dts[[k-1]]
k
dts[[k-1]][ngram]
dts[[k-1]][.("",ngram)]
.("",ngram)
list("",ngram)
dts[[k-1]][.(,ngram)]
dts[[k-1]][.(*,ngram)]
dtx1 <- dts[[k-1]][, Cols.chosen=c(token2,token3,token4,token5)]
dtx <- dts[[k-1]]
dtx[,c("token1"):=NULL]
dtx <- dtx[,c("token1"):=NULL]
dtx
dtx[ngram]
dtkm1 <- dts[[k-1]]
dtk <- dts[[k]]
setkey(dtkm1,token2,token3,token4,token5)
setkey(dtk,token2,token3,token4,token5)
dtk[agram]
setkey(dtk,token2,token3,token4)
dtk[agram]
CKNi <- nrow(dtkm1[ngram])
CKNitot <- nrow(dtk[agram])
CKNi
CKNitot
length(agram)
runApp()
k
runApp()
k
word
agram
k
ngram
dts[[k]]
k=
4
agram
word
runApp()
k
prob
lambda
D
CKNi
CKNitot
runApp()
ngram
dtkm1
nrow(dtkm1)
dtkm1[ngram]
nrow(dtkm1[ngram])/nrow(dtkm1)
runApp()
score
word
runApp()
k
a
prob
calPkn
word
agram
ngram
runApp()
lambda
D
CKNitot
dts[[k]]
agram
ngram
dts[[k]][agram]
CKNi
lambda
prob
lambda
CKNi
CKNitot
agram
ngram
word
prob
runApp()
k
ngram
dtkm1
dtkm1[ngram]
nrow(dtkm1[ngram])
nrow(dtkm1[ngram])/nrow(dtkm1)
prob
runApp()
prob
k
prob
k
ngram
runApp()
prob
runApp()
prob
runApp()
score
runApp()
nextwordtable
i
word
score
nrows
score
word
agram[i]
i
word
input$D
score
typeof(score)
length(scoer)
length(score)
runApp()
score
runApp()
score
ngramcount
nmigcount
nm1gcount
lambda
Q
runApp()
score
ncount
score
word
agram[[i]]
i
runApp()
score
runApp()
k
prob
CKNi
D
CKNitot
lambda
word
agram
runApp()
score
runApp()
score
agram
dtkm1
dtk
CKNi
CKNitot
lambda
agram
CKNi
CKNitot
lambda
dtkm1
dtk
k
dktm1
dtkm1
prob
k
CKNi
CKNitot
agram
ngram
k
nrow(dts[[k]][agram])
D /CKNitot
D
CKNitot
shiny::runApp()
score
shiny::runApp()
word
typeof(word)
ngrams[j]
ngrams[j][token5]
ngrams[j][[token5]]
ngrams[j]$token5
ngrams[j]["token5"]
ngrams[j][["token5"]]
runApp()
score
runApp()
score
runApp()
score
CKNi
ngram
dts[[k]][ngram]$count
dts[[k]]
agram
dts[[k]][ngram]
ngram
k
dts[[1]]
dts[[1]][ngram]
dts[[1]][agram]
Q
runApp()
score
ncount
score
runApp()
library(slidify)
author("Predict next word with a n-gram language model")
---
* The techniques of text mining and natural language processing, e.g. Stupid Backoff and Interpolated Kneser-Ney smoothing algorithms, are employed.
nrow(data1)
nrow(dts1)
library(shiny)
library(data.table)
# returns string w/o leading or trailing whitespace
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
# load ngram data set
dt1 <- as.data.table(read.table("dt1gram", row.names=NULL, header=T))
dt2 <- as.data.table(read.table("dt2gram", row.names=NULL, header=T))
dt3 <- as.data.table(read.table("dt3gram", row.names=NULL, header=T))
dt4 <- as.data.table(read.table("dt4gram", row.names=NULL, header=T))
dt5 <- as.data.table(read.table("dt5gram", row.names=NULL, header=T))
dir()
setwd("..")
dir()
library(shiny)
library(data.table)
# returns string w/o leading or trailing whitespace
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
# load ngram data set
dt1 <- as.data.table(read.table("dt1gram", row.names=NULL, header=T))
dt2 <- as.data.table(read.table("dt2gram", row.names=NULL, header=T))
dt3 <- as.data.table(read.table("dt3gram", row.names=NULL, header=T))
dt4 <- as.data.table(read.table("dt4gram", row.names=NULL, header=T))
dt5 <- as.data.table(read.table("dt5gram", row.names=NULL, header=T))
nrow(data1)
nrow(dts1)
nrow(dt1)
nrow(dt2)
nrow(dt3)
nrow(dt4)
nrow(dt5)
dir()
setwd("Predict next word with a n-gram language model/")
publish_github("anh065","nextwordpredict")
publish(title = 'Predict next work with n-gram model', 'index.html', host = 'rpubs')
publish_github("anh065","nextwordpredict")
R.home(component="home")
